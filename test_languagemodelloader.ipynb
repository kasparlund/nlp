{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of whether LanguageModelLoader deliver batch where each row is a continuous set of tokens\n",
    "\n",
    "\n",
    "Status is that the test works with\n",
    "\n",
    "-MyLanguageModelLoader \n",
    "\n",
    "-fastai's LanguageModelLoader, however, throws an exception while indexing the jagged array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * \n",
    "from languagemodelloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllBatches(data,epochs=1):\n",
    "    x=None\n",
    "    for i in range(epochs):\n",
    "        for xb,yb in data:\n",
    "            d= xb.data.numpy()\n",
    "            if x is None: \n",
    "                x = xb.data.numpy().copy()\n",
    "            else:         \n",
    "                x = np.concatenate((x, xb.data.numpy().copy()),axis=1)\n",
    "            continue\n",
    "    return x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateContinuousNumber(bs,seq_len,iterations,minTokens):\n",
    "    \"The data consist of continuously increasing numbers i jagged array with randomly varying layout\"\n",
    "    jagged = []\n",
    "    countTokens = 0\n",
    "    totalTokens = bs*seq_len*iterations\n",
    "    #print(f\"totalTokens:{totalTokens}\")\n",
    "    rand_interval=20\n",
    "    while countTokens < totalTokens:\n",
    "        nb = totalTokens-countTokens if   totalTokens-countTokens <rand_interval\\\n",
    "                                     else minTokens+int(np.random.random() * rand_interval)\n",
    "        jagged.append(np.arange(countTokens+1,countTokens+1+nb))\n",
    "        countTokens = jagged[-1][-1]\n",
    "    jagged = np.asarray(jagged)    \n",
    "    return jagged, countTokens\n",
    "\n",
    "def printJagged(jagged, countTokens):\n",
    "    print(f\"countTokens:{countTokens}\")\n",
    "    for j in jagged: print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_datadirection( bs,seq_len,iterations,minTokens, forward=True, nbInoutGenerations=10, log=False):\n",
    "    for i in range(nbInoutGenerations):\n",
    "        jagged,countTokens = generateContinuousNumber(bs,seq_len,iterations,minTokens)\n",
    "        if log: printJagged(jagged, countTokens)\n",
    "            \n",
    "        trainIDS = validIDS = jagged\n",
    "        db = TextLMDataBunch.from_ids( \".\", None, trainIDS, validIDS, bptt=seq_len, p_bptt=p_bptt, bs=bs)\n",
    "\n",
    "        data = MyLanguageModelLoader(dataset=db.train_dl, bptt=seq_len, p_bptt=p_bptt, bs=bs, shuffle=False, \n",
    "                                     backwards=not forward, log=log)\n",
    "        batches = getAllBatches(data)\n",
    "        if log: display(pd.DataFrame(data=batches))\n",
    "\n",
    "        #The diff from one to the next column must be 1 for aligned mini-batches with forward indexing of the data\n",
    "        #(forward is default for LanguageModelLoader ie.: backwards=False) \n",
    "        b_diff = batches[:,1:] - batches[:,0:-1]\n",
    "        if log: display(pd.DataFrame(data=b_diff))\n",
    "            \n",
    "        diff_value = 1 if forward else -1\n",
    "        assert (b_diff.flatten()==diff_value).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test continouity of tokens in batches loaded forwards and backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_ptt     = 0 for MyLanguageModelLoader\n",
    "p_bptt     =  0  #deactivates changes in the sequence length in MyLanguageModelLoader so that we do not wrap around\n",
    "\n",
    "#create test data so that we can control whether the LanguageModelLoader returns contigous tokens \n",
    "#The genrated data must be size so that the batches will not wrap aoround. \n",
    "bs         =  9\n",
    "seq_len    =  3  #=bptt\n",
    "iterations =  2\n",
    "minTokens  =  1 #in a rag array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.51 s, sys: 10.9 ms, total: 5.52 s\n",
      "Wall time: 5.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_datadirection( bs, seq_len, iterations, minTokens, forward=True, nbInoutGenerations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 s, sys: 23.6 ms, total: 6.25 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%time test_datadirection( bs, seq_len, iterations, minTokens, forward=False, nbInoutGenerations=10000, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
