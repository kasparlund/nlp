{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of whether LanguageModelLoader deliver batch where each row is a continuous set of tokens\n",
    "\n",
    "\n",
    "Status is that the test works with\n",
    "\n",
    "-MyLanguageModelLoader \n",
    "\n",
    "-fastai's LanguageModelLoader, however, throws an exception while indexing the jagged array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * \n",
    "import numpy as np\n",
    "from languagemodelloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalTokens:396\n",
      "countTokens:396\n",
      "[1 2 3 4 5 6 7]\n",
      "[ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26]\n",
      "[27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "[48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66]\n",
      "[67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84]\n",
      "[ 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101]\n",
      "[102 103 104 105 106 107 108 109 110 111 112 113 114]\n",
      "[115 116 117 118 119]\n",
      "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137]\n",
      "[138 139 140 141 142 143 144 145 146 147 148]\n",
      "[149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169]\n",
      "[170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191]\n",
      "[192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210]\n",
      "[211 212 213 214 215 216 217 218 219 220 221 222 223 224]\n",
      "[225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242]\n",
      "[243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263]\n",
      "[264 265 266 267 268 269 270 271 272]\n",
      "[273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292]\n",
      "[293 294 295 296 297 298 299 300 301 302 303 304 305]\n",
      "[306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324]\n",
      "[325 326 327 328 329 330 331]\n",
      "[332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347]\n",
      "[348 349 350 351 352 353 354 355 356 357 358 359 360]\n",
      "[361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378]\n",
      "[379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396]\n"
     ]
    }
   ],
   "source": [
    "#create test data so that we can control whether the LanguageModelLoader returns contigous tokens \n",
    "#set b_ptt to for the current verion of fastai' LanguageModelLoader and 0 for MyLanguageModelLoader\n",
    "#p_bptt    = .95 current verion of fastai' LanguageModelLoader \n",
    "p_bptt     =  0  #deactivates changes in the sequence length in MyLanguageModelLoader so that we do not wrap around\n",
    "seq_len    =  9  #ie bptt\n",
    "bs         =  4\n",
    "iterations = 11\n",
    "minTokens  =  4\n",
    "\n",
    "jagged = []\n",
    "countTokens = 0\n",
    "totalTokens = bs*seq_len*iterations\n",
    "print(f\"totalTokens:{totalTokens}\")\n",
    "rand_interval=20\n",
    "while countTokens < totalTokens:\n",
    "    nb = totalTokens-countTokens if   totalTokens-countTokens <rand_interval\\\n",
    "                                 else minTokens+int(np.random.random() * rand_interval)\n",
    "    jagged.append(np.arange(countTokens+1,countTokens+1+nb))\n",
    "    countTokens = jagged[-1][-1]\n",
    "jagged = np.asarray(jagged)    \n",
    "print(f\"countTokens:{countTokens}\")\n",
    "for j in jagged: print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIDS = validIDS = jagged\n",
    "db   = TextLMDataBunch.from_ids( \".\", None, trainIDS, validIDS, bptt=seq_len, p_bptt=p_bptt, bs=bs)\n",
    "data = MyLanguageModelLoader(dataset=db.train_dl, bptt=seq_len, p_bptt=p_bptt, bs=bs, shuffle=False)\n",
    "            \n",
    "def getAllBatches(data,epochs=1):\n",
    "    x=None\n",
    "    for i in range(epochs):\n",
    "        for xb,yb in data:\n",
    "            if x is None: x = xb[:,0:seq_len].data.numpy()\n",
    "            else:         x = np.concatenate((x, xb[:,0:seq_len].data.numpy()),axis=1)\n",
    "            continue\n",
    "    return x            \n",
    "batches = getAllBatches(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input was size to an batches that do not wrap aoround. Also the input contains continuously \n",
    "#increasing numbers. Therefore the diff below from one to the next column must be 1 for a properly aligned batches\n",
    "b_diff = batches[:,1:] - batches[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert b_diff.flatten().all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
