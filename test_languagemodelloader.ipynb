{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of whether LanguageModelLoader deliver batch where each row is a continuous set of tokens\n",
    "\n",
    "\n",
    "Status is that the test works with\n",
    "\n",
    "-MyLanguageModelLoader \n",
    "\n",
    "-fastai's LanguageModelLoader, however, throws an exception while indexing the jagged array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * \n",
    "from languagemodelloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printJagged_(jagged, count=-1):\n",
    "    if count>= 0: print(f\"count:{count}\")\n",
    "    for j in range(len(jagged)): print(f\"row {j}:{jagged[j]}\")\n",
    "def getAllBatches(data,epochs=1,log=False):\n",
    "    x=None\n",
    "    for i in range(epochs):\n",
    "        data.on_epoch_begin()            \n",
    "        countIte=0\n",
    "        for xb,yb in data:\n",
    "            countIte += 1\n",
    "            d= xb.data.numpy()            \n",
    "            if x is None: \n",
    "                x = xb.data.numpy().copy()\n",
    "            else:         \n",
    "                x = np.concatenate((x, xb.data.numpy().copy()),axis=1)\n",
    "            continue\n",
    "        #if log:\n",
    "        #    print(f\"epoch{i}\")    \n",
    "        #    display(pd.DataFrame(data=x))\n",
    "        #data.on_epoch_end()\n",
    "    return x,countIte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaggedArrayWithConsecutiveNumbers(nSentences,sentence_length,iterations,minTokens):\n",
    "    \"create jagged array with random layout and filled with consequetive numbers\"\n",
    "    jagged = []\n",
    "    count = 0\n",
    "    total = nSentences*sentence_length*iterations\n",
    "    while count < total:\n",
    "        nb = total-count if total-count<sentence_length else minTokens+int(np.random.random() * sentence_length)\n",
    "        jagged.append(np.arange(count+1,count+1+nb))\n",
    "        count = jagged[-1][-1]\n",
    "    jagged = np.asarray(jagged)    \n",
    "    return jagged, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.zeros(2)\n",
    "np.nonzero(1==a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get__ri(jagged, toks,backwards):\n",
    "    ri  = np.zeros_like(toks).flatten()-1\n",
    "    for i,t in enumerate(toks.flatten()):\n",
    "        for a in jagged:\n",
    "            ix = np.flatnonzero((a-t)==0)\n",
    "            if len(ix) == 0 : continue\n",
    "            if not backwards:\n",
    "                if ix[0]+1 < len(a): \n",
    "                    # there are tokens left in the sentence\n",
    "                    ri[i] = ix[0] \n",
    "            else:\n",
    "                if ix[0]>0: \n",
    "                    # there are tokens left in the sentence\n",
    "                    ri[i] = ix[0] \n",
    "                \n",
    "    ri = ri.reshape(toks.shape)\n",
    "    return ri\n",
    "    \n",
    "def test_datadirection( bs,seq_len,sentence_length, iterations, minTokens, nSentences, nEpochs=1,shuffle=False,\n",
    "                        backwards=False, nbInoutGenerations=10, log=False):\n",
    "    for i in range(nbInoutGenerations):\n",
    "        if log:print(\"\\nnew generation\")\n",
    "        jagged,countTokens = jaggedArrayWithConsecutiveNumbers(nSentences,sentence_length,iterations,minTokens)\n",
    "        if log: printJagged_(jagged)\n",
    "        \n",
    "        trainIDS = validIDS = jagged\n",
    "        db      = TextLMDataBunch.from_ids( \".\", None, trainIDS, validIDS, bptt=seq_len, bs=bs, no_check=True)\n",
    "        #data    = MyLanguageModelPreLoader(db.train_ds, bs, seq_len, backwards=backwards, shuffle=False, log=False)\n",
    "        data    = LanguageModelPreLoader(db.train_ds, bs=bs, bptt=seq_len, backwards=backwards, shuffle=shuffle)\n",
    "        dl      = DataLoader(data, bs, shuffle=False)\n",
    "        batches, countIte = getAllBatches(dl,nEpochs,log)\n",
    "        if log: \n",
    "            print(\"concatenated batchs\")\n",
    "            display(pd.DataFrame(data=batches))\n",
    "\n",
    "        assert countIte==len(dl), f\"number of iteration does not match: countIte:{countIte}!= len(data):{len(dl)} \"\n",
    "        \n",
    "        #The diff from one to the next column must be 1 for aligned mini-batches with forward indexing of the data\n",
    "        #(forward is default for LanguageModelLoader ie.: backwards=False) \n",
    "        \n",
    "        diff_value = -1 if backwards else 1\n",
    "        nr,nc = batches.shape\n",
    "        if nEpochs==1:\n",
    "            #test first epoch were all rows must be continuous\n",
    "            b_diff = batches[:,1:nc] - batches[:,0:nc-1]\n",
    "            if log: \n",
    "                print(\"column diffs\")\n",
    "                display(pd.DataFrame(data=b_diff))\n",
    "            assert (b_diff.flatten()==diff_value).all(), \"the sequences of iterations are rows are not contiguous\"\n",
    "            \n",
    "            #test that one row continue where the previous row ended\n",
    "            ix = np.arange(1,bs)\n",
    "            assert np.all(batches[ix-1,nc-1]+diff_value == batches[ix,0]), f\"last token i row-1 {batches[ix-1,seq_len-1]}+{diff} must be equal to first element in row:{batches[ix,0]}\"\n",
    "\n",
    "        #locate start of next batch \n",
    "        ixs    = np.arange(1,nEpochs)*(seq_len*iterations)\n",
    "        b_diff = batches[:,ixs] - batches[:,ixs-1]\n",
    "        \n",
    "        #get the current ofsset into the jagged array. ie if the offset > 0 then the sentence is not \n",
    "        #finished and must continue in the nest batch\n",
    "        ri = get__ri(jagged,batches[:,ixs-1],backwards) #get offset in jagged for the last token in the batch\n",
    "        b_sub_diff = b_diff[ri>=0]\n",
    "        #if log: \n",
    "        #    print(f\"get__ri.toks:\\n{batches[:,ixs-1]}\\nri:\\n{ri}\")\n",
    "        #    print(f\"diff_value {diff_value} \\nb_diff:\\n{b_diff}\\nb_sub_diff:\\n{b_sub_diff}\")\n",
    "        if b_sub_diff.size > 0: \n",
    "            assert (b_sub_diff.flatten()==diff_value).all(), f\"broken sequences ri:\\n{ri}\\nb_diff:\\n{b_diff}\"\n",
    "        elif log: \n",
    "            print(f\"no expected continuity between batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test continuouity of tokens in batches loaded forwards and backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### create test data so that we can control whether the LanguageModelLoader returns contigous tokens \n",
    "#The genrated data must be size so that the batches will not wrap aoround. \n",
    "bs         =  64\n",
    "seq_len    =  3  #=bptt\n",
    "sentence_length = 10*seq_len\n",
    "iterations =  1\n",
    "minTokens  =  1 #in a rag array\n",
    "shuffle    =  True\n",
    "nSentences = 6*bs\n",
    "nEpochs    =  2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_datadirection( bs, seq_len, sentence_length, iterations, minTokens, nSentences, nEpochs=1, shuffle=shuffle, \n",
    "                         backwards=False, nbInoutGenerations=1, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to initialize ro,ri:1.2e-03\n",
      "Time to shuffle: 1.6e-04\n",
      "time to initialize ro,ri:9.5e-04\n",
      "Time to shuffle: 1.7e-04\n",
      "time to initialize ro,ri:9.4e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:1.4e-03\n",
      "Time to shuffle: 1.7e-04\n",
      "time to initialize ro,ri:9.7e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:8.9e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:9.3e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:9.1e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:9.8e-04\n",
      "Time to shuffle: 1.4e-04\n",
      "time to initialize ro,ri:8.6e-04\n",
      "Time to shuffle: 1.4e-04\n"
     ]
    }
   ],
   "source": [
    "test_datadirection( bs, seq_len, sentence_length, iterations, minTokens, nSentences, nEpochs=nEpochs, shuffle=shuffle, \n",
    "                         backwards=False, nbInoutGenerations=10, log=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_datadirection( bs, seq_len,  sentence_length, iterations, minTokens, nSentences,\n",
    "                    nEpochs=1, shuffle=shuffle, backwards=True, nbInoutGenerations=1, log=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_datadirection( bs, seq_len,  sentence_length, iterations, minTokens, nSentences,\n",
    "                    nEpochs=nEpochs, shuffle=shuffle, backwards=True, nbInoutGenerations=10000, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
