{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a language model based on wikipedia in you language \n",
    "\n",
    "The notebooke includes the whole process but you will need to help the process if the following problem happens:  \n",
    "-you internet connection is interrupted (stage 1)\n",
    "\n",
    "-you run out of diskspace\n",
    "\n",
    "-because of the huge memory consumption. creatig the databunch for the training requires lots of memory\n",
    "\n",
    "\n",
    "In order ot handle these problemn the notebook is divided into stages. If the process is failes in a stage then you can resume the processing from the beginning of that stage by:\n",
    "-restarting the kernel \"Kernel\"/Restart & Clear Output\n",
    "\n",
    "-running the cells in stage 0: initialization\n",
    "\n",
    "-running the cells from the start of the stage that failed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0: Initialisation\n",
    "lang: You must set the parameter \"lang\" to the language you want to build a model for. Fx:\n",
    "\n",
    "fr: for french\n",
    "\n",
    "en: for english\n",
    "\n",
    "de:for german\n",
    "\n",
    "da: for danish \n",
    "\n",
    "etc.\n",
    "\n",
    "pathData: You must se the location where you want your data stored using the parameter pathData. Consider using a ssd-rive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang=\"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import * \n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import *\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathData       = Path(\"../../data/nlp\")\n",
    "path           = pathData / lang\n",
    "pathDump       = path/\"wiki-dump\"\n",
    "pathJson       = path/\"wiki-json\"\n",
    "\n",
    "pathTrainValid = path/\"wiki-train_valid\"\n",
    "pathTxt        = pathTrainValid/\"txt\"\n",
    "pathToks       = pathTrainValid/\"toks\"\n",
    "pathcsv        = pathTrainValid/\"wiki.csv\"\n",
    "\n",
    "cache_name   = \"sp-model\"\n",
    "pathVocab    = pathTrainValid / cache_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requried libraries: \n",
    "conda install -c anaconda psutil \n",
    "\n",
    "conda install -c anaconda git \n",
    "\n",
    "#conda install -c menpo wget \n",
    "conda install curl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: download the selected language from wikipedia and convert the articles to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(list(pathDump.glob(\"*.bz2\")))==0:\n",
    "    pathDump.mkdir(parents=True,exist_ok=True)\n",
    "    #fn  = f\"{lang}wiki-latest-pages-articles.xml.bz2\"\n",
    "    fn  = f\"{lang}wiki-latest-pages-articles-multistream.xml.bz2\"\n",
    "    url = f\"https://dumps.wikimedia.org/{lang}wiki/latest/{fn}\"\n",
    "    #cmd = f\"wget -c --no-check-certificate --show-progress {str(url)} -P {str(pathDump)}\"\n",
    "    cmd = f'curl -k -C - -o \"{str(pathDump/fn)}\" \"{str(url)}\"'\n",
    "    print(f\"If the command fails in the notebook then copy the command and run it in the terminal:{cmd}\")\n",
    "    ! $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Convert wikipedia dump to articles in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathWikiExtractor = Path(\"../wikiextractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pathJson.exists():\n",
    "    !git clone https://github.com/attardi/wikiextractor.git $pathWikiExtractor\n",
    "    cmd = f\"cd {str(pathWikiExtractor)} && python setup.py install\"\n",
    "    ! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not pathJson.exists():\n",
    "    #extracting the json-files. This takes about 1 hour for french with files read from and saved to a ssd hardrive \n",
    "    fn_wikidump = list(pathDump.iterdir())[0]\n",
    "    cmd = f\"cd {str(pathWikiExtractor)} && python WikiExtractor.py -o {str(pathJson)} --json --processes {defaults.cpus} -q  {str(fn_wikidump)}\"\n",
    "    print(f\"If WikiExtractor fails in the notebook then copy the command and run it in the terminal:{cmd}\")\n",
    "    ! $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: building a vocabulary using sentencepiece\n",
    "\n",
    "Now we separate the title of the wikipedia section from text section that we keep. \n",
    "\n",
    "In order to makes a first reduction on the number of section we clean the text with the preprocessing rules from fastai and ignore text with less than \"minWords\"\n",
    "\n",
    "You must set the lenght of the shortes sections you want to keep using the parameter \"minWords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minWords  = 10\n",
    "chunksize = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\kl\\appdata\\local\\conda\\conda\\envs\\fastai\\lib\\site-packages (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_sentencepiece import *\n",
    "from filetokenizer import *\n",
    "from languagemodelloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pathTxt.exists():\n",
    "    swm = SentencepieceWikiModel(lang=lang, pathJson=pathJson, pathcsv=pathcsv, pathTxt=pathTxt, pathVocab=pathVocab, minWords=minWords )    \n",
    "    %time swm.wikijson2TrainingData()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not (pathVocab/\"m.model\").exists():\n",
    "    swm = SentencepieceWikiModel(lang=lang, pathJson=pathJson, pathcsv=pathcsv, pathTxt=pathTxt, pathVocab=pathVocab, minWords=minWords)\n",
    "    %time swm.trainVocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (pathVocab/\"itos.pkl\").exists():\n",
    "    swm = SentencepieceWikiModel(lang=lang, pathJson=pathJson, pathcsv=pathcsv, pathTxt=pathTxt, pathVocab=pathVocab, minWords=minWords)\n",
    "    swm.convertVocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some examples using the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Size of vocabulary: 32000\n",
      "2: ['▁She', '▁is', '▁tall', '.', '▁He', '▁is', '▁small']\n",
      "3: [118, 18, 3920, 9, 40, 18, 322]\n"
     ]
    }
   ],
   "source": [
    "swm = SentencepieceWikiModel(lang=lang, pathJson=pathJson, pathcsv=pathcsv, pathTxt=pathTxt, pathVocab=pathVocab, minWords=minWords)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(pathVocab / \"m.model\"))\n",
    "print(\"1: Size of vocabulary:\",sp.GetPieceSize())\n",
    "sentence = \"She is tall. He is small\"\n",
    "print(\"2:\", sp.EncodeAsPieces(sentence))\n",
    "print(\"3:\", sp.EncodeAsIds(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control symbol\n",
      "<unk>(0)\n",
      "\n",
      "user_defined_symbols\n",
      "xxfld(0)\n",
      "xxmaj(3)\n",
      "xxup(4)\n",
      "xxrep(5)\n",
      "xxwrep(6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Control symbol\")\n",
    "for s in [\"<unk>\"]: print(f\"{s}({sp.PieceToId(s)})\")\n",
    "\n",
    "print(f\"\\nuser_defined_symbols\")\n",
    "for s in swm.getUserdefinedSymbols():print(f\"{s}({sp.PieceToId(s)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training of the language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tokenizer\n",
    "The sentencepiece vocabulary was trained in Train Sentencepiece tokenizer.ipynb.\n",
    "\n",
    "Here we will make a BasicTokenizer from Sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer SentencepieceTokenizer in en with the following rules:\n",
      " - fix_html\n",
      " - replace_rep\n",
      " - replace_wrep\n",
      " - spec_add_spaces\n",
      " - rm_useless_spaces\n",
      " - rm_extra_lineshift\n",
      " - replace_all_caps\n",
      " - deal_caps\n",
      "\n",
      "size og vocabulary: 32000\n",
      "pad_idx: 0\n",
      "[0, 1, 0, 3, 4, 5, 6, 0]\n",
      "vocab: <fastai.text.transform.Vocab object at 0x000002719CC0DE80>\n"
     ]
    }
   ],
   "source": [
    "spt_func  = partial(SentencepieceTokenizer.create, pathVocab=pathVocab)\n",
    "spt_func.__name__ = SentencepieceTokenizer.__name__\n",
    "spt       = spt_func(lang=\"en\")\n",
    "tokenizer = Tokenizer(spt_func,\"en\")\n",
    "\n",
    "pad_idx   = spt.vocab().numericalize([text.transform.PAD])[0]\n",
    "vocab,max_vocab  = spt.vocab(), len(spt.vocab().itos)\n",
    "\n",
    "print(tokenizer)\n",
    "print(\"size og vocabulary:\", max_vocab)\n",
    "print(\"pad_idx:\",pad_idx)\n",
    "\n",
    "print(spt.vocab().numericalize( [\"<unk>\" ,\"xxbos\" ,\"xxpad\" ,\"xxmaj\" ,\"xxup\" ,\"xxrep\" ,\"xxwrep\", \"xxfld\"]  ))\n",
    "sentence = [\"She is tall.\", \"He is small\"]\n",
    "tokenizer._process_all_1(sentence)\n",
    "\n",
    "print(\"vocab:\",vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM Training\n",
    "Set the minimum number of tokens for the sections that we shall retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discard section with kess than \"minTok\" tokens\n",
    "minToks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.dtype:<class 'numpy.int16'>\n",
      "self.dtype:<class 'numpy.int16'>\n",
      "Tokenizer SentencepieceTokenizer in en with the following rules:\n",
      " - fix_html\n",
      " - replace_rep\n",
      " - replace_wrep\n",
      " - spec_add_spaces\n",
      " - rm_useless_spaces\n",
      " - rm_extra_lineshift\n",
      " - rm_extra_lineshift\n",
      " - replace_all_caps\n",
      " - deal_caps\n",
      "\n",
      "size og vocabulary: 32000\n",
      "pad_idx: 0\n",
      "[0, 1, 0, 3, 4, 5, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "pad_idx   = spt.vocab().numericalize([text.transform.PAD])[0]\n",
    "vocab,max_vocab = spt.vocab(), len(spt.vocab().itos)\n",
    "trainTokenizer = FileTokenizer(pathToks/\"train\", spt_func,\"en\",vocab,minToks=minToks,n_cpus=max(defaults.cpus-1,1))\n",
    "validTokenizer = FileTokenizer(pathToks/\"valid\", spt_func,\"en\",vocab,minToks=minToks,n_cpus=max(defaults.cpus-1,1))\n",
    "\n",
    "print(trainTokenizer)\n",
    "print(\"size og vocabulary:\", max_vocab)\n",
    "print(\"pad_idx:\",pad_idx)\n",
    "\n",
    "print(spt.vocab().numericalize( [\"<unk>\" ,\"xxbos\" ,\"xxpad\" ,\"xxmaj\" ,\"xxup\" ,\"xxrep\" ,\"xxwrep\", \"xxfld\"]  ))\n",
    "#sentence = [\"She is tall.\", \"He is small\"]\n",
    "#tokenizer._process_all_1(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files   = np.asarray( list(pathTxt.glob(\"*.txt\")) )\n",
    "nrows   = len(files)\n",
    "split   = 0.2\n",
    "splitindex, index = int(nrows*split+.5), np.random.permutation(np.arange(nrows)) \n",
    "\n",
    "chunksize=0\n",
    "\n",
    "trainList = TextList( files[:-splitindex], vocab=vocab, pad_idx=pad_idx, \n",
    "                      processor=[FileTokenizeProcessor(tokenizer=trainTokenizer, \n",
    "                                                       chunksize=chunksize, mark_fields=False)])\n",
    "\n",
    "validList = TextList( files[-splitindex:], vocab=vocab, pad_idx=pad_idx, \n",
    "                      processor=[FileTokenizeProcessor(tokenizer=validTokenizer, \n",
    "                                                       chunksize=chunksize, mark_fields=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (pathToks/\"train\").exists():\n",
    "    %time trainList.process()\n",
    "    trainList=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (pathToks/\"valid\").exists():\n",
    "    %time p = validList.process()\n",
    "    validList=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%time trainIDS = trainTokenizer.getIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%time validIDS=validTokenizer.getIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning:    number of arrays:27391909 - number of ids:-2019910006\n",
      "Validation: number of arrays:6560301 - number of ids:548245997\n",
      "Lenght of token rags min:10 max:13667 - median:66.0\n",
      "rags > 1000 tokes:878\n",
      "Wall time: 9.14 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Traning:    number of arrays:{len(trainIDS)} - number of ids:{np.sum([len(ids) for ids in trainIDS])}\")\n",
    "print(f\"Validation: number of arrays:{len(validIDS)} - number of ids:{np.sum([len(ids) for ids in validIDS])}\")\n",
    "\n",
    "#Analyse the distribution of the legnth of tokens sequences in the ragged/jagged array of tokes\n",
    "sectionlengths = np.asarray([len(s) for s in trainIDS],dtype=np.int32)\n",
    "plt.hist(sectionlengths[sectionlengths<1000], 100, density=True, facecolor='g', alpha=0.75)\n",
    "np.histogram(sectionlengths[sectionlengths<1000],50)\n",
    "\n",
    "print(f\"Lenght of token rags min:{min(sectionlengths)} max:{np.max(sectionlengths)} - median:{np.median(sectionlengths)}\")\n",
    "print(f\"rags > 1000 tokes:{np.sum(sectionlengths>1000)}\")\n",
    "sectionlengths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%  percentile\n",
      "25  35\n",
      "50  66\n",
      "75  111\n",
      "90  166\n",
      "97  241\n",
      "99  314\n",
      "100  13667\n"
     ]
    }
   ],
   "source": [
    "percent     = np.asarray([ 25,50,75,90,97,99,100]) # %np.arange(101,dtype=np.int)\n",
    "percentiles = np.percentile(sectionlengths,percent).astype(np.int)\n",
    "print(\"%  percentile\")\n",
    "for i in range(len(percent)):print(f\"{percent[i]}  {percentiles[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTextLMDataBunch def create\n",
      "LanguageModelLoader.__init__ batches:23933 nToks:53608199 bptt:70 p_bptt:0 shuffle:True backwards:False\n",
      "LanguageModelLoader.__init__ batches:3461 nToks:7751422 bptt:70 p_bptt:0 shuffle:False backwards:False\n",
      "LanguageModelLoader.__init__ batches:23933 nToks:53608199 bptt:70 p_bptt:0 shuffle:False backwards:False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500000, 100000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from languagemodelloader import *\n",
    "#i have an issue with passing pad_idx\n",
    "\n",
    "#uses nTrainToks, nValidToks to limit the number of tokens used for training/validation\n",
    "#nTrainToks, nValidToks = 1000,200\n",
    "#nTrainToks, nValidToks = int(5e5),int(2e5)\n",
    "nTrainToks, nValidToks = int(5e5),int(1e5)\n",
    "#nTrainToks, nValidToks = 3000,600\n",
    "if nTrainToks>0 and nValidToks>0:\n",
    "    trainIDS_ = trainIDS[0:nTrainToks]\n",
    "    validIDS_ = validIDS[0:nValidToks]\n",
    "else:\n",
    "    trainIDS_ = trainIDS\n",
    "    validIDS_ = validIDS\n",
    "\n",
    "dblm = MyTextLMDataBunch.from_ids( pathTrainValid, vocab, trainIDS_, validIDS_, bptt=70, p_bptt=0, bs=32)\n",
    "#dblm = TextLMDataBunch.from_ids( pathTrainValid, vocab, trainIDS_, validIDS_, bptt=70, p_bptt=1, bs=32)\n",
    "nTrainToks, nValidToks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dblm.train_ds.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageModelLoader.allocate_buffers shuffle:True backwards:False\n",
      "2 bl:1 __iter__ self.bl is BatchLayout.Parallel.True\n",
      "self.ite_len:23933 dataset.x.items:500000self.idx:500000 step:15625\n",
      "self.ei:\n",
      "[     0  15625  31250  46875  62500  78125  93750 109375 125000 140625 156250 171875 187500 203125 218750 234375 250000\n",
      " 265625 281250 296875 312500 328125 343750 359375 375000 390625 406250 421875 437500 453125 468750 484375]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>▁pla ko to , xxup ▁f ev ga ▁and ▁port es ▁are ▁three ▁versions ▁of ▁back gam mon ▁played ▁in xxunk . ▁together , ▁the ▁three ▁are ▁referred ▁to ▁as xxunk li . xxunk d eau ▁joined ▁the xxunk ▁law ▁firm ▁he en an xxunk iki e ▁as ▁counsel ▁and ▁settled ▁in ▁the ▁historic xxunk son ▁cor mi er ▁in xxunk ▁following ▁his ▁retirement ▁from ▁politics . ▁though ▁he</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>▁show ▁elections ▁are ▁a ▁common ▁event ▁in ▁dictator ial ▁regime s ▁that ▁feel ▁the ▁need ▁to ▁fe ign ▁the ▁appearance ▁of ▁public ▁legitimacy . ▁published ▁results ▁usually ▁show ▁nearly ▁100% ▁voter ▁turnout ▁and ▁high ▁support ▁( close ▁to ▁100% ▁in ▁many ▁cases ) ▁for ▁the ▁prescribed ▁candidate ( s ) ▁or ▁for ▁the ▁referendum ▁choice ▁that ▁favor s ▁the ▁political ▁party ▁in ▁power . ▁di ct ator ial ▁regime</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>▁if ▁it ▁exists ▁and ▁say ▁that ▁the ▁family ▁\" a \" ▁is ▁un condition ally ▁sum m able . ▁say ing ▁that ▁the ▁sum ▁\" s \" ▁is ▁the ▁limit ▁of ▁finite ▁partial ▁sum s ▁means ▁that ▁for ▁every ▁neighborhood ▁\" v \" ▁of ▁0 ▁in ▁\" x \", ▁there ▁is ▁a ▁finite ▁subset ▁\" a \" ▁of ▁\" i \" ▁such ▁that ▁if ▁formula _ 40 ▁and ▁formula</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>▁there ▁is ▁a ▁second ▁smaller ▁a ero drome ▁near xxunk wood ▁drive . xxunk e wen ▁air field ▁( xxup cc g 4 ) ▁is ▁a ▁private ▁air st rip ▁used ▁for ▁general ▁aviation . ▁sky d ive ▁mon c ton ▁operates ▁the ▁province ' s ▁only ▁nationally ▁certified ▁sports ▁parachute ▁club ▁out ▁of ▁this ▁facility . ▁under ▁the ▁rule ▁of ▁president ▁el - s isi , ▁in ▁march</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>▁in ▁the ▁de posi tory ▁institution s ▁de regulation ▁and ▁monetary ▁control ▁act ▁of ▁1980, ▁congress ▁re af firm ed ▁that ▁the ▁federal ▁reserve ▁should ▁promote ▁an ▁efficient ▁nationwide ▁payments ▁system . ▁the ▁act ▁subjects ▁all ▁deposit ory ▁institutions , ▁not ▁just ▁member ▁commercial ▁banks , ▁to ▁reserve ▁requirements ▁and ▁grants ▁them ▁equal ▁access ▁to ▁reserve ▁bank ▁payment ▁services . ▁other ▁tribute s ▁planned ▁for ▁the ▁anniversary ▁included ▁exhibitions</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dblm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%time learn = language_model_learner(dblm, drop_mult=0, qrnn=False, pad_token=-1, callback_fns=ShowGraph)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#problematic at present\n",
    "%time learn.lr_find()\n",
    "learn.recorder.plot(skip_start=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ipygpulogger import IPyGPULogger\n",
    "il = IPyGPULogger().start()\n",
    "torch.ones((1, 1)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 38:57<5:50:40]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.704093</th>\n",
       "    <th>4.871644</th>\n",
       "    <th>0.237032</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2016' class='' max='3461', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      58.25% [2016/3461 01:06<00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bl:1 __iter__ self.bl is BatchLayout.Parallel.True\n",
      "self.ite_len:23933 dataset.x.items:500000self.idx:500000 step:15625\n",
      "self.ei:\n",
      "[     0  15625  31250  46875  62500  78125  93750 109375 125000 140625 156250 171875 187500 203125 218750 234375 250000\n",
      " 265625 281250 296875 312500 328125 343750 359375 375000 390625 406250 421875 437500 453125 468750 484375]\n",
      "LanguageModelLoader.allocate_buffers shuffle:False backwards:False\n",
      "2 bl:1 __iter__ self.bl is BatchLayout.Parallel.True\n",
      "self.ite_len:3461 dataset.x.items:100000self.idx:100000 step:3125\n",
      "self.ei:\n",
      "[    0  3125  6250  9375 12500 15625 18750 21875 25000 28125 31250 34375 37500 40625 43750 46875 50000 53125 56250\n",
      " 59375 62500 65625 68750 71875 75000 78125 81250 84375 87500 90625 93750 96875]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bl:1 __iter__ self.bl is BatchLayout.Parallel.True\n",
      "self.ite_len:23933 dataset.x.items:500000self.idx:500000 step:15625\n",
      "self.ei:\n",
      "[     0  15625  31250  46875  62500  78125  93750 109375 125000 140625 156250 171875 187500 203125 218750 234375 250000\n",
      " 265625 281250 296875 312500 328125 343750 359375 375000 390625 406250 421875 437500 453125 468750 484375]\n",
      "2 bl:1 __iter__ self.bl is BatchLayout.Parallel.True\n",
      "self.ite_len:3461 dataset.x.items:100000self.idx:100000 step:3125\n",
      "self.ei:\n",
      "[    0  3125  6250  9375 12500 15625 18750 21875 25000 28125 31250 34375 37500 40625 43750 46875 50000 53125 56250\n",
      " 59375 62500 65625 68750 71875 75000 78125 81250 84375 87500 90625 93750 96875]\n"
     ]
    }
   ],
   "source": [
    "#%load_ext line_profiler\n",
    "%time learn.fit_one_cycle(10,2e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5e5//5//400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model-32k-sentencepiece-vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(363) LOG(INFO) Done: 100% characters are covered.\n",
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(373) LOG(INFO) Alphabet size=5727\n",
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(374) LOG(INFO) Final character coverage=1\n",
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(406) LOG(INFO) Done! preprocessed 998659 sentences.\n",
    "C:\\projects\\sentencepiece\\src\\unigram_model_trainer.cc(129) LOG(INFO) Making suffix array...\n",
    "[I 14:36:20.223 NotebookApp] Saving file at /nlp/nonsens scratchpad.ipynb\n",
    "C:\\projects\\sentencepiece\\src\\unigram_model_trainer.cc(133) LOG(INFO) Extracting frequent sub strings...\n",
    "C:\\projects\\sentencepiece\\src\\unigram_model_trainer.cc(184) LOG(INFO) Initialized 1000000 seed sentencepieces\n",
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(412) LOG(INFO) Tokenizing input sentences with whitespace: 998659\n",
    "C:\\projects\\sentencepiece\\src\\trainer_interface.cc(421) LOG(INFO) Done! 2058688\n",
    "C:\\projects\\sentencepiece\\src\\unigram_model_trainer.cc(472) LOG(INFO) Using 2058688 sentences for EM training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
